#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import math
import numpy as np
import pandas as pd

# --- Config (edit if needed) ---
INPUT_XLSX = r"Tesco_Input_bucketed.xlsx"
OUTPUT_CSV = r"Tesco_Balanced_Callfile.csv"
TARGET_N = 165
ID_COL = "TES Store #"
# Updated stratification columns
STRAT_COLS = ["Country", "Region", "Store_Format", "Staffing_Type", "Toy_Mod"]
RANDOM_STATE = 42

# --- Helpers ---
def _alloc_proportional_with_min(total, capacities, min_per_stratum=1):
    """
    Allocate samples proportionally to stratum sizes, ensuring minimum allocation.
    """
    keys = list(capacities.keys())
    if not keys or total <= 0:
        return {k: 0 for k in keys}
    
    # Calculate total population
    total_pop = sum(capacities.values())
    if total_pop == 0:
        return {k: 0 for k in keys}
    
    # First, try to give minimum to each stratum
    min_total = len(keys) * min_per_stratum
    if total < min_total:
        # If we can't give minimum to all, distribute evenly
        base = total // len(keys)
        remainder = total % len(keys)
        alloc = {k: min(base, capacities[k]) for k in keys}
        
        # Distribute remainder to largest strata first
        sorted_keys = sorted(keys, key=lambda k: capacities[k], reverse=True)
        for i in range(remainder):
            k = sorted_keys[i % len(sorted_keys)]
            if alloc[k] < capacities[k]:
                alloc[k] += 1
        return alloc
    
    # Give minimum to each stratum first
    alloc = {k: min(min_per_stratum, capacities[k]) for k in keys}
    remaining = total - sum(alloc.values())
    
    # Distribute remaining proportionally
    if remaining > 0:
        # Calculate proportions for remaining allocation
        remaining_capacity = {k: capacities[k] - alloc[k] for k in keys}
        remaining_total = sum(remaining_capacity.values())
        
        if remaining_total > 0:
            for k in keys:
                if remaining_capacity[k] > 0:
                    prop = remaining_capacity[k] / remaining_total
                    additional = min(int(remaining * prop), remaining_capacity[k])
                    alloc[k] += additional
            
            # Distribute any final remainder
            final_remaining = total - sum(alloc.values())
            sorted_keys = sorted(keys, key=lambda k: remaining_capacity[k], reverse=True)
            for i in range(final_remaining):
                k = sorted_keys[i % len(sorted_keys)]
                if alloc[k] < capacities[k]:
                    alloc[k] += 1
    
    return alloc

def create_stratum_key(row, strat_cols):
    """Create a tuple key for stratification from multiple columns."""
    return tuple(str(row[col]).strip().upper() if pd.notna(row[col]) else 'UNKNOWN' 
                for col in strat_cols)

def _sample_from_stratum(stratum, n, rng):
    """Sample n rows from a stratum."""
    if n <= 0 or stratum.empty:
        return stratum.head(0)
    
    n_available = len(stratum)
    n_sample = min(n, n_available)
    
    return stratum.sample(n=n_sample, random_state=rng.integers(0, 1_000_000))

# --- Main ---
if __name__ == "__main__":
    rng = np.random.default_rng(RANDOM_STATE)

    # Load Excel
    df = pd.read_excel(INPUT_XLSX)
    print(f"Loaded {len(df)} rows from {INPUT_XLSX}")

    # Basic validation
    if ID_COL not in df.columns:
        raise KeyError(f"Missing required ID column: {ID_COL}")
    
    missing_cols = [col for col in STRAT_COLS if col not in df.columns]
    if missing_cols:
        raise KeyError(f"Missing stratification columns: {missing_cols}")

    # Clean the data
    df = df.dropna(subset=[ID_COL]).copy()
    print(f"After removing rows with missing ID: {len(df)} rows")

    # Standardize stratification columns
    for col in STRAT_COLS:
        if col in df.columns:
            df[col] = df[col].astype(str).str.strip().str.upper()

    # Create stratification groups
    df['_stratum_key'] = df.apply(lambda row: create_stratum_key(row, STRAT_COLS), axis=1)
    
    # Get stratum information
    stratum_counts = df['_stratum_key'].value_counts()
    print(f"\nFound {len(stratum_counts)} unique strata")
    print("Top 10 largest strata:")
    for stratum, count in stratum_counts.head(10).items():
        print(f"  {stratum}: {count} stores")

    # Calculate allocation per stratum
    capacities = stratum_counts.to_dict()
    total_target = min(TARGET_N, len(df))
    quotas = _alloc_proportional_with_min(total_target, capacities, min_per_stratum=1)

    print(f"\nTarget sample size: {total_target}")
    print(f"Planned allocation across {len([q for q in quotas.values() if q > 0])} strata")

    # Sample from each stratum
    selected_parts = []
    for stratum_key, quota in quotas.items():
        if quota <= 0:
            continue
            
        stratum_data = df[df['_stratum_key'] == stratum_key]
        sampled = _sample_from_stratum(stratum_data, quota, rng)
        
        if not sampled.empty:
            selected_parts.append(sampled)

    # Combine all selected samples
    if selected_parts:
        selected = pd.concat(selected_parts, ignore_index=True)
    else:
        selected = df.head(0)

    # Top-up if some strata were smaller than expected
    if len(selected) < total_target:
        need = total_target - len(selected)
        remaining = df[~df[ID_COL].astype(str).isin(selected[ID_COL].astype(str))]
        
        if not remaining.empty:
            additional = remaining.sample(n=min(need, len(remaining)), 
                                        random_state=rng.integers(0, 1_000_000))
            selected = pd.concat([selected, additional], ignore_index=True)
            print(f"Added {len(additional)} additional samples to reach target")

    # Remove the temporary stratum key column
    if '_stratum_key' in selected.columns:
        selected = selected.drop('_stratum_key', axis=1)

    # Save results
    selected.to_csv(OUTPUT_CSV, index=False)
    print(f"\n=== RESULTS ===")
    print(f"Saved: {OUTPUT_CSV}")
    print(f"Selected: {len(selected)} stores")

    # Summary statistics
    for col in STRAT_COLS:
        if col in selected.columns:
            print(f"\nBy {col}:")
            counts = selected[col].value_counts().sort_index()
            for value, count in counts.items():
                print(f"  {value}: {count}")

    # Cross-tabulation for key dimensions (if reasonable size)
    if len(selected) > 0:
        print(f"\n=== CROSS-TABULATION SUMMARY ===")
        try:
            # Show distribution across multiple dimensions
            if 'Country' in selected.columns and 'Store_Format' in selected.columns:
                cross_tab = pd.crosstab(selected['Country'], selected['Store_Format'], margins=True)
                print("\nCountry vs Store_Format:")
                print(cross_tab)
        except Exception as e:
            print(f"Could not generate cross-tabulation: {e}")
